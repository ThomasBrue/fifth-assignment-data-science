{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science - Assignment 5 - Comparative Experimentation\n",
    "\n",
    "Dataset: <b>Covtype</b>     (large dataset)\n",
    "\n",
    "Thomas Bründl\n",
    "\n",
    "se21m032\n",
    "\n",
    "<br>\n",
    "\n",
    "### Approach\n",
    "\n",
    "In this exercise I experimented with three different algorithms (KNN, Perceptron, Decission Tree).\n",
    "The input parameters of the respective algorithms were varied to determine how this would affect Effectiveness and Efficiency.\n",
    "\n",
    "\n",
    "### Evaluation method\n",
    "\n",
    "For each dataset, I investigated 2 parameters to determine Efficiency:\n",
    "\n",
    "1. Training time\n",
    "2. Testing time\n",
    "\n",
    "To determine Effectiveness I took a look at 4 different parameters:\n",
    "\n",
    "1. Accuracy score\n",
    "2. Jaccard score\n",
    "3. f1 score\n",
    "4. Precision score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as time\n",
    "import statistics\n",
    "from tabulate import tabulate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2959.365301</td>\n",
       "      <td>155.656807</td>\n",
       "      <td>14.103704</td>\n",
       "      <td>269.428217</td>\n",
       "      <td>46.418855</td>\n",
       "      <td>2350.146611</td>\n",
       "      <td>212.146049</td>\n",
       "      <td>223.318716</td>\n",
       "      <td>142.528263</td>\n",
       "      <td>1980.291226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090392</td>\n",
       "      <td>0.077716</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.026803</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>2.051471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>279.984734</td>\n",
       "      <td>111.913721</td>\n",
       "      <td>7.488242</td>\n",
       "      <td>212.549356</td>\n",
       "      <td>58.295232</td>\n",
       "      <td>1559.254870</td>\n",
       "      <td>26.769889</td>\n",
       "      <td>19.768697</td>\n",
       "      <td>38.274529</td>\n",
       "      <td>1324.195210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286743</td>\n",
       "      <td>0.267725</td>\n",
       "      <td>0.052584</td>\n",
       "      <td>0.056957</td>\n",
       "      <td>0.014310</td>\n",
       "      <td>0.022641</td>\n",
       "      <td>0.161508</td>\n",
       "      <td>0.152307</td>\n",
       "      <td>0.121791</td>\n",
       "      <td>1.396504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1859.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-173.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2809.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1106.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2996.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>1710.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3163.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>3328.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3858.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>7117.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>7173.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0              1              2              3   \\\n",
       "count  581012.000000  581012.000000  581012.000000  581012.000000   \n",
       "mean     2959.365301     155.656807      14.103704     269.428217   \n",
       "std       279.984734     111.913721       7.488242     212.549356   \n",
       "min      1859.000000       0.000000       0.000000       0.000000   \n",
       "25%      2809.000000      58.000000       9.000000     108.000000   \n",
       "50%      2996.000000     127.000000      13.000000     218.000000   \n",
       "75%      3163.000000     260.000000      18.000000     384.000000   \n",
       "max      3858.000000     360.000000      66.000000    1397.000000   \n",
       "\n",
       "                  4              5              6              7   \\\n",
       "count  581012.000000  581012.000000  581012.000000  581012.000000   \n",
       "mean       46.418855    2350.146611     212.146049     223.318716   \n",
       "std        58.295232    1559.254870      26.769889      19.768697   \n",
       "min      -173.000000       0.000000       0.000000       0.000000   \n",
       "25%         7.000000    1106.000000     198.000000     213.000000   \n",
       "50%        30.000000    1997.000000     218.000000     226.000000   \n",
       "75%        69.000000    3328.000000     231.000000     237.000000   \n",
       "max       601.000000    7117.000000     254.000000     254.000000   \n",
       "\n",
       "                  8              9   ...             45             46  \\\n",
       "count  581012.000000  581012.000000  ...  581012.000000  581012.000000   \n",
       "mean      142.528263    1980.291226  ...       0.090392       0.077716   \n",
       "std        38.274529    1324.195210  ...       0.286743       0.267725   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%       119.000000    1024.000000  ...       0.000000       0.000000   \n",
       "50%       143.000000    1710.000000  ...       0.000000       0.000000   \n",
       "75%       168.000000    2550.000000  ...       0.000000       0.000000   \n",
       "max       254.000000    7173.000000  ...       1.000000       1.000000   \n",
       "\n",
       "                  47             48             49             50  \\\n",
       "count  581012.000000  581012.000000  581012.000000  581012.000000   \n",
       "mean        0.002773       0.003255       0.000205       0.000513   \n",
       "std         0.052584       0.056957       0.014310       0.022641   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  51             52             53             54  \n",
       "count  581012.000000  581012.000000  581012.000000  581012.000000  \n",
       "mean        0.026803       0.023762       0.015060       2.051471  \n",
       "std         0.161508       0.152307       0.121791       1.396504  \n",
       "min         0.000000       0.000000       0.000000       1.000000  \n",
       "25%         0.000000       0.000000       0.000000       1.000000  \n",
       "50%         0.000000       0.000000       0.000000       2.000000  \n",
       "75%         0.000000       0.000000       0.000000       2.000000  \n",
       "max         1.000000       1.000000       1.000000       7.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'covtype.data', header=None)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hold Out Method\n",
    "\n",
    "The first 53 columns (x) are used as independet variables to predict the dependent variable y which represents the column 54. \n",
    "\n",
    "The data (rows) is split into train and test data with a ratio of 66/33. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.loc[:,:53], data.loc[:,54:], test_size=0.33, random_state=1524401)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN (k-nearest neighbors)\n",
    "\n",
    "KNN was tested with the kd-tree algorithm and three different input parameters were chosen as neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--[KNN]----[Mean Results]---------------------------------------------\n",
      "mean training time: 10.97989821434021\n",
      "mean testing time: 17.78772298494975\n",
      "mean accuracy score: 0.963042548530777\n",
      "mean jaccard score: 0.9289282118980144\n",
      "mean f1 score: 0.9629408779632805\n",
      "mean precision score: 0.9630232642959531\n"
     ]
    }
   ],
   "source": [
    "train_times = []\n",
    "test_times = []\n",
    "\n",
    "accuracy_scores = []\n",
    "jaccard_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "neighbors = [3, 5, 8]\n",
    "\n",
    "for n_neighbors in neighbors:\n",
    "    # print(\"--[KNN]----[n_neighbors: \" + str(n_neighbors) + \"]---------------------------------------------\")\n",
    "\n",
    "    algo = KNeighborsClassifier(n_neighbors=n_neighbors, algorithm='kd_tree')\n",
    "\n",
    "    # train ----------------------------------------------------\n",
    "    start_training = time.time()\n",
    "    model = algo.fit(X=X_train, y=y_train.values.ravel())\n",
    "    training_time = time.time() - start_training\n",
    "    # print(\"training_time: \" + str(training_time))\n",
    "    train_times.append(training_time)\n",
    "\n",
    "    # predict ----------------------------------------------------\n",
    "    start_testing = time.time()\n",
    "    y_pred = model.predict(X=X_test)\n",
    "    test_time = time.time() - start_testing\n",
    "    # print(\"test_time: \" + str(test_time))\n",
    "    test_times.append(test_time)\n",
    "\n",
    "    # --- accuracy -------------------------------------------------------------------\n",
    "    accuracy_score_result = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    # print(\"accuracy: \" + str(accuracy_score_result))\n",
    "    accuracy_scores.append(accuracy_score_result)\n",
    "\n",
    "    # --- jaccard -------------------------------------------------------------------\n",
    "    jaccard_score_result = jaccard_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "    # print(\"jaccard: \" + str(jaccard_score_result))\n",
    "    jaccard_scores.append(jaccard_score_result)\n",
    "\n",
    "    # --- f1 -------------------------------------------------------------------\n",
    "    f1_score_result = f1_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "    # print(\"f1_score: \" + str(f1_score_result))\n",
    "    f1_scores.append(f1_score_result)\n",
    "\n",
    "    # --- precision -------------------------------------------------------------------\n",
    "    precision_score_result = precision_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "    # print(\"precision_score: \" + str(precision_score_result))\n",
    "    precision_scores.append(precision_score_result)\n",
    "    \n",
    "\n",
    "print(\"--[KNN]----[Mean Results]---------------------------------------------\")\n",
    "\n",
    "mean_training_time = statistics.mean(train_times)\n",
    "mean_testing_time = statistics.mean(test_times)\n",
    "\n",
    "print(\"mean training time: \" + str(mean_training_time))\n",
    "print(\"mean testing time: \" + str(mean_testing_time))\n",
    "\n",
    "mean_accuracy_score = statistics.mean(accuracy_scores)\n",
    "mean_jaccard_score = statistics.mean(jaccard_scores)\n",
    "mean_f1_score = statistics.mean(f1_scores)\n",
    "mean_precision_score = statistics.mean(precision_scores)\n",
    "\n",
    "print(\"mean accuracy score: \" + str(mean_accuracy_score))\n",
    "print(\"mean jaccard score: \" + str(mean_jaccard_score))\n",
    "print(\"mean f1 score: \" + str(mean_f1_score))\n",
    "print(\"mean precision score: \" + str(mean_precision_score))\n",
    "\n",
    "knn_mean_training_time = mean_training_time\n",
    "knn_mean_testing_time = mean_testing_time\n",
    "\n",
    "knn_mean_accuracy_score = mean_accuracy_score\n",
    "knn_mean_jaccard_score = mean_jaccard_score\n",
    "knn_mean_f1_score = mean_f1_score\n",
    "knn_mean_precision_score = mean_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN - Analyze the results based on different input parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " train_times\n",
      "+-------------+---------+---------+---------+\n",
      "| neighbors   |       3 |       5 |       8 |\n",
      "+=============+=========+=========+=========+\n",
      "|             | 11.4612 | 10.7346 | 10.7439 |\n",
      "+-------------+---------+---------+---------+\n",
      "\n",
      " test_times\n",
      "+-------------+---------+---------+---------+\n",
      "| neighbors   |       3 |       5 |       8 |\n",
      "+=============+=========+=========+=========+\n",
      "|             | 14.5399 | 17.4712 | 21.3521 |\n",
      "+-------------+---------+---------+---------+\n",
      "\n",
      " accuracy_scores\n",
      "+-------------+----------+----------+----------+\n",
      "| neighbors   |        3 |        5 |        8 |\n",
      "+=============+==========+==========+==========+\n",
      "|             | 0.966281 | 0.964555 | 0.958291 |\n",
      "+-------------+----------+----------+----------+\n",
      "\n",
      " jaccard_scores\n",
      "+-------------+----------+----------+----------+\n",
      "| neighbors   |        3 |        5 |        8 |\n",
      "+=============+==========+==========+==========+\n",
      "|             | 0.934965 | 0.931737 | 0.920083 |\n",
      "+-------------+----------+----------+----------+\n",
      "\n",
      " f1_scores\n",
      "+-------------+----------+----------+----------+\n",
      "| neighbors   |        3 |        5 |        8 |\n",
      "+=============+==========+==========+==========+\n",
      "|             | 0.966241 | 0.964483 | 0.958099 |\n",
      "+-------------+----------+----------+----------+\n",
      "\n",
      " precision_scores\n",
      "+-------------+----------+----------+----------+\n",
      "| neighbors   |        3 |        5 |        8 |\n",
      "+=============+==========+==========+==========+\n",
      "|             | 0.966237 | 0.964478 | 0.958355 |\n",
      "+-------------+----------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "eval_criteria = [train_times, test_times, accuracy_scores, jaccard_scores, f1_scores, precision_scores]\n",
    "eval_criteria_name = [\"train_times\", \"test_times\", \"accuracy_scores\", \"jaccard_scores\", \"f1_scores\", \"precision_scores\"]\n",
    "\n",
    "i = 0\n",
    "for criteria in eval_criteria:\n",
    "    print(\"\\n \" + eval_criteria_name[i])\n",
    "\n",
    "    headers = [\"neighbors\", \"3\", \"5\", \"8\"]\n",
    "    table_data = [[\"\"]]\n",
    "\n",
    "    for idx, neighbor in enumerate(neighbors):\n",
    "        table_data[0].append(eval_criteria[i][idx])\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test time increases when the neighbours count is increased.\n",
    "All other evaluation criteria are not substantially  influenced by the varying neighbours count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "The perceptron was tested with different alphas (0.0001, 0.00001, 0.001) and penalties (l2, l1, elasticnet).\n",
    "I can conclude that an alpha of 0.0001 will produce the best runtime result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--[Perceptron]----[Mean Results]---------------------------------------------\n",
      "Take only the first element of the train_times and the test_times list due to highly volatile behaviour of the train_time when it comes to alpha (0.00001, 0.001).\n",
      "This means when we take a alpha of 0.00001 or 0.001 then the train_time is increased substantially.\n",
      "I choose to take only the first instance into account that is performed with a alpha of 0.0001 to not produce a misleading training result.\n",
      "mean training time: 5.926147222518921\n",
      "mean testing time: 0.06399273872375488\n",
      "mean accuracy score: 0.4574149603095956\n",
      "mean jaccard score: 0.2683143990277549\n",
      "mean f1 score: 0.3802636686106108\n",
      "mean precision score: 0.5165258227665548\n"
     ]
    }
   ],
   "source": [
    "train_times = []\n",
    "test_times = []\n",
    "\n",
    "accuracy_scores = []\n",
    "jaccard_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "alphas = [0.0001, 0.00001, 0.001]\n",
    "penalties = ['l2', 'l1', 'elasticnet']\n",
    "\n",
    "for alpha in alphas:\n",
    "    for penalty in penalties:\n",
    "\n",
    "        # print(\"--[Perceptron]----[alpha: \" + str(alpha) + \"]-----[penalty: \" + str(penalty) + \"]----------------------------------------\")\n",
    "\n",
    "        algo = Perceptron(alpha=alpha, penalty=penalty, random_state=1524401)\n",
    "\n",
    "        # train ----------------------------------------------------\n",
    "        start_training = time.time()\n",
    "        model = algo.fit(X=X_train, y=y_train.values.ravel())\n",
    "        training_time = time.time() - start_training\n",
    "        # print(\"training_time: \" + str(training_time))\n",
    "        train_times.append(training_time)\n",
    "\n",
    "        # predict ----------------------------------------------------\n",
    "        start_testing = time.time()\n",
    "        y_pred = model.predict(X=X_test)\n",
    "        test_time = time.time() - start_testing\n",
    "        # print(\"test_time: \" + str(test_time))\n",
    "        test_times.append(test_time)\n",
    "\n",
    "        # --- accuracy -------------------------------------------------------------------\n",
    "        accuracy_score_result = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "        # print(\"accuracy: \" + str(accuracy_score_result))\n",
    "        accuracy_scores.append(accuracy_score_result)\n",
    "\n",
    "        # --- jaccard -------------------------------------------------------------------\n",
    "        jaccard_score_result = jaccard_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "        # print(\"jaccard: \" + str(jaccard_score_result))\n",
    "        jaccard_scores.append(jaccard_score_result)\n",
    "\n",
    "        # --- f1 -------------------------------------------------------------------\n",
    "        f1_score_result = f1_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "        # print(\"f1_score: \" + str(f1_score_result))\n",
    "        f1_scores.append(f1_score_result)\n",
    "\n",
    "        # --- precision -------------------------------------------------------------------\n",
    "        precision_score_result = precision_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "        # print(\"precision_score: \" + str(precision_score_result))\n",
    "        precision_scores.append(precision_score_result)\n",
    "    \n",
    "\n",
    "print(\"--[Perceptron]----[Mean Results]---------------------------------------------\")\n",
    "\n",
    "\n",
    "print(\"Take only the first element of the train_times and the test_times list due to highly volatile behaviour of the train_time when it comes to alpha (0.00001, 0.001).\")\n",
    "print(\"This means when we take a alpha of 0.00001 or 0.001 then the train_time is increased substantially.\")\n",
    "print(\"I choose to take only the first instance into account that is performed with a alpha of 0.0001 to not produce a misleading training result.\")\n",
    "mean_training_time = train_times[0]\n",
    "mean_testing_time = test_times[0]\n",
    "\n",
    "print(\"mean training time: \" + str(mean_training_time))\n",
    "print(\"mean testing time: \" + str(mean_testing_time))\n",
    "\n",
    "mean_accuracy_score = statistics.mean(accuracy_scores)\n",
    "mean_jaccard_score = statistics.mean(jaccard_scores)\n",
    "mean_f1_score = statistics.mean(f1_scores)\n",
    "mean_precision_score = statistics.mean(precision_scores)\n",
    "\n",
    "print(\"mean accuracy score: \" + str(mean_accuracy_score))\n",
    "print(\"mean jaccard score: \" + str(mean_jaccard_score))\n",
    "print(\"mean f1 score: \" + str(mean_f1_score))\n",
    "print(\"mean precision score: \" + str(mean_precision_score))\n",
    "\n",
    "perceptron_mean_training_time = mean_training_time\n",
    "perceptron_mean_testing_time = mean_testing_time\n",
    "\n",
    "perceptron_mean_accuracy_score = mean_accuracy_score\n",
    "perceptron_mean_jaccard_score = mean_jaccard_score\n",
    "perceptron_mean_f1_score = mean_f1_score\n",
    "perceptron_mean_precision_score = mean_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron - Analyze the results based on different input parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " train_times\n",
      "+-----------------+----------+-----------+---------+\n",
      "| penalty\\alpha   |   0.0001 |   0.00001 |   0.001 |\n",
      "+=================+==========+===========+=========+\n",
      "| l2              |  5.92615 |   78.3912 | 95.4666 |\n",
      "+-----------------+----------+-----------+---------+\n",
      "| l1              |  6.65738 |   32.1401 | 11.1099 |\n",
      "+-----------------+----------+-----------+---------+\n",
      "| elasticnet      |  6.19961 |   31.7278 | 70.091  |\n",
      "+-----------------+----------+-----------+---------+\n",
      "\n",
      " test_times\n",
      "+-----------------+-----------+-----------+-----------+\n",
      "| penalty\\alpha   |    0.0001 |   0.00001 |     0.001 |\n",
      "+=================+===========+===========+===========+\n",
      "| l2              | 0.0639927 | 0.0560403 | 0.0590091 |\n",
      "+-----------------+-----------+-----------+-----------+\n",
      "| l1              | 0.0620506 | 0.057003  | 0.0580032 |\n",
      "+-----------------+-----------+-----------+-----------+\n",
      "| elasticnet      | 0.0668502 | 0.0640521 | 0.0600488 |\n",
      "+-----------------+-----------+-----------+-----------+\n",
      "\n",
      " accuracy_scores\n",
      "+-----------------+----------+-----------+----------+\n",
      "| penalty\\alpha   |   0.0001 |   0.00001 |    0.001 |\n",
      "+=================+==========+===========+==========+\n",
      "| l2              | 0.526964 |  0.538001 | 0.487942 |\n",
      "+-----------------+----------+-----------+----------+\n",
      "| l1              | 0.502545 |  0.619029 | 0.41337  |\n",
      "+-----------------+----------+-----------+----------+\n",
      "| elasticnet      | 0.481813 |  0.429225 | 0.117846 |\n",
      "+-----------------+----------+-----------+----------+\n",
      "\n",
      " jaccard_scores\n",
      "+-----------------+----------+-----------+-----------+\n",
      "| penalty\\alpha   |   0.0001 |   0.00001 |     0.001 |\n",
      "+=================+==========+===========+===========+\n",
      "| l2              | 0.336103 |  0.312631 | 0.238394  |\n",
      "+-----------------+----------+-----------+-----------+\n",
      "| l1              | 0.315588 |  0.428562 | 0.195524  |\n",
      "+-----------------+----------+-----------+-----------+\n",
      "| elasticnet      | 0.236243 |  0.283255 | 0.0685299 |\n",
      "+-----------------+----------+-----------+-----------+\n",
      "\n",
      " f1_scores\n",
      "+-----------------+----------+-----------+----------+\n",
      "| penalty\\alpha   |   0.0001 |   0.00001 |    0.001 |\n",
      "+=================+==========+===========+==========+\n",
      "| l2              | 0.480389 |  0.436805 | 0.320811 |\n",
      "+-----------------+----------+-----------+----------+\n",
      "| l1              | 0.460695 |  0.57178  | 0.295027 |\n",
      "+-----------------+----------+-----------+----------+\n",
      "| elasticnet      | 0.319834 |  0.413968 | 0.123063 |\n",
      "+-----------------+----------+-----------+----------+\n",
      "\n",
      " precision_scores\n",
      "+-----------------+----------+-----------+----------+\n",
      "| penalty\\alpha   |   0.0001 |   0.00001 |    0.001 |\n",
      "+=================+==========+===========+==========+\n",
      "| l2              | 0.484731 |  0.566339 | 0.478207 |\n",
      "+-----------------+----------+-----------+----------+\n",
      "| l1              | 0.504423 |  0.589513 | 0.391815 |\n",
      "+-----------------+----------+-----------+----------+\n",
      "| elasticnet      | 0.3109   |  0.660941 | 0.661865 |\n",
      "+-----------------+----------+-----------+----------+\n"
     ]
    }
   ],
   "source": [
    "eval_criteria = [train_times, test_times, accuracy_scores, jaccard_scores, f1_scores, precision_scores]\n",
    "eval_criteria_name = [\"train_times\", \"test_times\", \"accuracy_scores\", \"jaccard_scores\", \"f1_scores\", \"precision_scores\"]\n",
    "i = 0\n",
    "for criteria in eval_criteria:\n",
    "    print(\"\\n \" + eval_criteria_name[i])\n",
    "    headers = [\"penalty\\\\alpha\", \"0.0001\", \"0.00001\", \"0.001\"]\n",
    "    table_data = []\n",
    "    for idy, y in enumerate(penalties):\n",
    "        table_data.append([penalties[idy]])\n",
    "        for idx, x in enumerate(alphas):\n",
    "            table_data[idy].append(eval_criteria[i][len(alphas)*idy+idx])\n",
    "    \n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the penalty is set to \"l2\" and alpha is increased (e.g. from 0.0001 to 0.001) then the training time increases substantially (i.e. 95 seconds).\n",
    "\n",
    "Varying the penalty does not produce significantly different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "The decision tree was tested with different min_samples_splits (2, 50, 100, 500, 1000) and min_samples_leafs (1, 50, 100, 500, 1000).\n",
    "\n",
    "When using a min_samples_split of 2 and a min_samples_leafs of 1000 a training time of only 3.87374 can be achieved. However when chosing this configuration the accuracy_score decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--[DecisionTree]----[Mean Results]---------------------------------------------\n",
      "mean training time: 4.568159532546997\n",
      "mean testing time: 0.06457931518554688\n",
      "mean accuracy score: 0.8640700136647648\n",
      "mean jaccard score: 0.7656439620799526\n",
      "mean f1 score: 0.8630173329961914\n",
      "mean precision score: 0.8631774455252602\n"
     ]
    }
   ],
   "source": [
    "train_times = []\n",
    "test_times = []\n",
    "\n",
    "accuracy_scores = []\n",
    "jaccard_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "min_samples_splits = [2, 50, 100, 500, 1000]\n",
    "min_samples_leafs = [1, 50, 100, 500, 1000]\n",
    "\n",
    "\n",
    "for min_samples_split in min_samples_splits:\n",
    "    for min_samples_leaf in min_samples_leafs:\n",
    "        # print(\"--[DecisionTree]----[min_samples_splits: \" + str(min_samples_split) + \"]-----[min_samples_leafs: \" + str(min_samples_leaf) + \"]----------------------------------------\")\n",
    "\n",
    "        algo = DecisionTreeClassifier(criterion='gini', splitter='best', min_samples_split=min_samples_split, random_state=1524401)\n",
    "\n",
    "        # train ----------------------------------------------------\n",
    "        start_training = time.time()\n",
    "        model = algo.fit(X=X_train, y=y_train.values.ravel())\n",
    "        training_time = time.time() - start_training\n",
    "        # print(\"training_time: \" + str(training_time))\n",
    "        train_times.append(training_time)\n",
    "\n",
    "        # predict ----------------------------------------------------\n",
    "        start_testing = time.time()\n",
    "        y_pred = model.predict(X=X_test)\n",
    "        test_time = time.time() - start_testing\n",
    "        # print(\"test_time: \" + str(test_time))\n",
    "        test_times.append(test_time)\n",
    "\n",
    "        # --- accuracy -------------------------------------------------------------------\n",
    "        accuracy_score_result = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "        # print(\"accuracy: \" + str(accuracy_score_result))\n",
    "        accuracy_scores.append(accuracy_score_result)\n",
    "\n",
    "        # --- jaccard -------------------------------------------------------------------\n",
    "        jaccard_score_result = jaccard_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "        # print(\"jaccard: \" + str(jaccard_score_result))\n",
    "        jaccard_scores.append(jaccard_score_result)\n",
    "\n",
    "        # --- f1 -------------------------------------------------------------------\n",
    "        f1_score_result = f1_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "        # print(\"f1_score: \" + str(f1_score_result))\n",
    "        f1_scores.append(f1_score_result)\n",
    "\n",
    "        # --- precision -------------------------------------------------------------------\n",
    "        precision_score_result = precision_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "        # print(\"precision_score: \" + str(precision_score_result))\n",
    "        precision_scores.append(precision_score_result)\n",
    "\n",
    "\n",
    "print(\"--[DecisionTree]----[Mean Results]---------------------------------------------\")\n",
    "\n",
    "mean_training_time = statistics.mean(train_times)\n",
    "mean_testing_time = statistics.mean(test_times)\n",
    "\n",
    "print(\"mean training time: \" + str(mean_training_time))\n",
    "print(\"mean testing time: \" + str(mean_testing_time))\n",
    "\n",
    "mean_accuracy_score = statistics.mean(accuracy_scores)\n",
    "mean_jaccard_score = statistics.mean(jaccard_scores)\n",
    "mean_f1_score = statistics.mean(f1_scores)\n",
    "mean_precision_score = statistics.mean(precision_scores)\n",
    "\n",
    "print(\"mean accuracy score: \" + str(mean_accuracy_score))\n",
    "print(\"mean jaccard score: \" + str(mean_jaccard_score))\n",
    "print(\"mean f1 score: \" + str(mean_f1_score))\n",
    "print(\"mean precision score: \" + str(mean_precision_score))\n",
    "\n",
    "decisionTree_mean_training_time = mean_training_time\n",
    "decisionTree_mean_testing_time = mean_testing_time\n",
    "\n",
    "decisionTree_mean_accuracy_score = mean_accuracy_score\n",
    "decisionTree_mean_jaccard_score = mean_jaccard_score\n",
    "decisionTree_mean_f1_score = mean_f1_score\n",
    "decisionTree_mean_precision_score = mean_precision_score  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree - Analyze the results based on different input parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " train_times\n",
      "+----------------+---------+---------+---------+---------+---------+\n",
      "|   leafs\\splits |       2 |      50 |     100 |     500 |    1000 |\n",
      "+================+=========+=========+=========+=========+=========+\n",
      "|              1 | 5.42151 | 5.25915 | 4.99193 | 4.96798 | 4.94437 |\n",
      "+----------------+---------+---------+---------+---------+---------+\n",
      "|             50 | 4.85013 | 4.82666 | 4.86817 | 4.84664 | 4.85455 |\n",
      "+----------------+---------+---------+---------+---------+---------+\n",
      "|            100 | 4.74569 | 4.73399 | 4.74066 | 4.71897 | 4.71965 |\n",
      "+----------------+---------+---------+---------+---------+---------+\n",
      "|            500 | 4.1875  | 4.18849 | 4.24311 | 4.22385 | 4.24498 |\n",
      "+----------------+---------+---------+---------+---------+---------+\n",
      "|           1000 | 3.87374 | 3.89623 | 3.90543 | 3.87415 | 4.07646 |\n",
      "+----------------+---------+---------+---------+---------+---------+\n",
      "\n",
      " test_times\n",
      "+----------------+-----------+-----------+-----------+-----------+-----------+\n",
      "|   leafs\\splits |         2 |        50 |       100 |       500 |      1000 |\n",
      "+================+===========+===========+===========+===========+===========+\n",
      "|              1 | 0.072994  | 0.0730686 | 0.0759997 | 0.0720434 | 0.070601  |\n",
      "+----------------+-----------+-----------+-----------+-----------+-----------+\n",
      "|             50 | 0.06795   | 0.0679932 | 0.0679948 | 0.0698009 | 0.0680554 |\n",
      "+----------------+-----------+-----------+-----------+-----------+-----------+\n",
      "|            100 | 0.0667162 | 0.0650623 | 0.0671225 | 0.0659981 | 0.0666199 |\n",
      "+----------------+-----------+-----------+-----------+-----------+-----------+\n",
      "|            500 | 0.0577927 | 0.0597522 | 0.0579472 | 0.0570016 | 0.0580015 |\n",
      "+----------------+-----------+-----------+-----------+-----------+-----------+\n",
      "|           1000 | 0.0539513 | 0.0540004 | 0.0530005 | 0.0580494 | 0.0669663 |\n",
      "+----------------+-----------+-----------+-----------+-----------+-----------+\n",
      "\n",
      " accuracy_scores\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|   leafs\\splits |        2 |       50 |      100 |      500 |     1000 |\n",
      "+================+==========+==========+==========+==========+==========+\n",
      "|              1 | 0.933596 | 0.933596 | 0.933596 | 0.933596 | 0.933596 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|             50 | 0.902281 | 0.902281 | 0.902281 | 0.902281 | 0.902281 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|            100 | 0.879907 | 0.879907 | 0.879907 | 0.879907 | 0.879907 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|            500 | 0.814816 | 0.814816 | 0.814816 | 0.814816 | 0.814816 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|           1000 | 0.78975  | 0.78975  | 0.78975  | 0.78975  | 0.78975  |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "\n",
      " jaccard_scores\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|   leafs\\splits |        2 |       50 |      100 |      500 |     1000 |\n",
      "+================+==========+==========+==========+==========+==========+\n",
      "|              1 | 0.876216 | 0.876216 | 0.876216 | 0.876216 | 0.876216 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|             50 | 0.823105 | 0.823105 | 0.823105 | 0.823105 | 0.823105 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|            100 | 0.786804 | 0.786804 | 0.786804 | 0.786804 | 0.786804 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|            500 | 0.688327 | 0.688327 | 0.688327 | 0.688327 | 0.688327 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|           1000 | 0.653768 | 0.653768 | 0.653768 | 0.653768 | 0.653768 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "\n",
      " f1_scores\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|   leafs\\splits |        2 |       50 |      100 |      500 |     1000 |\n",
      "+================+==========+==========+==========+==========+==========+\n",
      "|              1 | 0.933598 | 0.933598 | 0.933598 | 0.933598 | 0.933598 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|             50 | 0.902098 | 0.902098 | 0.902098 | 0.902098 | 0.902098 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|            100 | 0.879479 | 0.879479 | 0.879479 | 0.879479 | 0.879479 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|            500 | 0.812693 | 0.812693 | 0.812693 | 0.812693 | 0.812693 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|           1000 | 0.787218 | 0.787218 | 0.787218 | 0.787218 | 0.787218 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "\n",
      " precision_scores\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|   leafs\\splits |        2 |       50 |      100 |      500 |     1000 |\n",
      "+================+==========+==========+==========+==========+==========+\n",
      "|              1 | 0.933608 | 0.933608 | 0.933608 | 0.933608 | 0.933608 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|             50 | 0.902011 | 0.902011 | 0.902011 | 0.902011 | 0.902011 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|            100 | 0.879322 | 0.879322 | 0.879322 | 0.879322 | 0.879322 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|            500 | 0.813469 | 0.813469 | 0.813469 | 0.813469 | 0.813469 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n",
      "|           1000 | 0.787477 | 0.787477 | 0.787477 | 0.787477 | 0.787477 |\n",
      "+----------------+----------+----------+----------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "eval_criteria = [train_times, test_times, accuracy_scores, jaccard_scores, f1_scores, precision_scores]\n",
    "eval_criteria_name = [\"train_times\", \"test_times\", \"accuracy_scores\", \"jaccard_scores\", \"f1_scores\", \"precision_scores\"]\n",
    "i = 0\n",
    "for criteria in eval_criteria:\n",
    "    print(\"\\n \" + eval_criteria_name[i])\n",
    "    headers = [\"leafs\\splits\", \"2\", \"50\", \"100\", \"500\", \"1000\"]\n",
    "    table_data = []\n",
    "    for idy, y in enumerate(min_samples_leafs):\n",
    "        table_data.append([min_samples_leafs[idy]])\n",
    "        for idx, x in enumerate(min_samples_splits):\n",
    "            table_data[idy].append(eval_criteria[i][len(min_samples_leafs)*idy+idx])\n",
    "    \n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results (KNN, Perceptron, Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+-------------+------------+-----------+----------+-------------+\n",
      "|               |   Train time |   Test time |   Accuracy |   Jaccard |       f1 |   Precision |\n",
      "+===============+==============+=============+============+===========+==========+=============+\n",
      "| K-NN          |     10.9799  |  17.7877    |   0.963043 |  0.928928 | 0.962941 |    0.963023 |\n",
      "+---------------+--------------+-------------+------------+-----------+----------+-------------+\n",
      "| Perceptron    |      5.92615 |   0.0639927 |   0.457415 |  0.268314 | 0.380264 |    0.516526 |\n",
      "+---------------+--------------+-------------+------------+-----------+----------+-------------+\n",
      "| Decision Tree |      4.56816 |   0.0645793 |   0.86407  |  0.765644 | 0.863017 |    0.863177 |\n",
      "+---------------+--------------+-------------+------------+-----------+----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "headers = [\"\", \"Train time\", \"Test time\", \"Accuracy\", \"Jaccard\", \"f1\", \"Precision\"]\n",
    "\n",
    "table_data = [\n",
    "    [\"K-NN\", str(knn_mean_training_time), str(knn_mean_testing_time), str(knn_mean_accuracy_score),  str(knn_mean_jaccard_score), str(knn_mean_f1_score), str(knn_mean_precision_score)],\n",
    "    [\"Perceptron\",  str(perceptron_mean_training_time), str(perceptron_mean_testing_time), str(perceptron_mean_accuracy_score),  str(perceptron_mean_jaccard_score), str(perceptron_mean_f1_score), str(perceptron_mean_precision_score)],\n",
    "    [\"Decision Tree\",str(decisionTree_mean_training_time), str(decisionTree_mean_testing_time), str(decisionTree_mean_accuracy_score),  str(decisionTree_mean_jaccard_score), str(decisionTree_mean_f1_score), str(decisionTree_mean_precision_score)],\n",
    "]\n",
    "\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prceptron and the decision tree achieve good efficiency. The train time and test time are similar with the perceptron and the decision tree.\n",
    "\n",
    "KNN is not really efficient compared to the other methods. However KNN does achieve a very high accuracy, Jaccard, f1 and precission.\n",
    "\n",
    "The decission tree seems to be the best suited method for this data set. It provides very low training and testing time and produces a very high precision of 0.86.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5721b1f7d2d92434e9e5c3fe27cc3896d312ac295c31b1e6c49bf4bc7e5d2a55"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
